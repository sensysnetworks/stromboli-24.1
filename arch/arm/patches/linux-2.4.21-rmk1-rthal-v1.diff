diff -urN linux-2.4.21-rmk1/arch/arm/config.in linux-2.4.21-rmk1-rthal/arch/arm/config.in
--- linux-2.4.21-rmk1/arch/arm/config.in	2003-07-18 09:56:35.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/config.in	2003-07-22 13:27:48.000000000 +0200
@@ -483,6 +483,9 @@
    fi
 fi
 bool 'Networking support' CONFIG_NET
+
+bool 'RTAI Realtime Hardware abstraction Layer' CONFIG_RTHAL
+
 bool 'System V IPC' CONFIG_SYSVIPC
 bool 'BSD Process Accounting' CONFIG_BSD_PROCESS_ACCT
 bool 'Sysctl support' CONFIG_SYSCTL
diff -urN linux-2.4.21-rmk1/arch/arm/kernel/armksyms.c linux-2.4.21-rmk1-rthal/arch/arm/kernel/armksyms.c
--- linux-2.4.21-rmk1/arch/arm/kernel/armksyms.c	2003-07-18 09:56:35.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/kernel/armksyms.c	2003-07-22 13:27:48.000000000 +0200
@@ -20,6 +20,10 @@
 #include <linux/interrupt.h>
 #include <linux/pm.h>
 #include <linux/vt_kern.h>
+#ifdef CONFIG_RTHAL
+#include <linux/console.h>
+#include <linux/sched.h>
+#endif
 
 #include <asm/byteorder.h>
 #include <asm/elf.h>
@@ -105,6 +109,9 @@
 
 EXPORT_SYMBOL_NOVERS(__do_softirq);
 
+#ifdef CONFIG_RTHAL
+EXPORT_SYMBOL(console_drivers);
+#endif
 	/* platform dependent support */
 EXPORT_SYMBOL(dump_thread);
 EXPORT_SYMBOL(dump_fpu);
@@ -254,10 +261,13 @@
 EXPORT_SYMBOL(elf_hwcap);
 
 	/* syscalls */
+#ifndef CONFIG_RTHAL
+/* exported elsewhere when CONFIG_RTHAL is on */
 EXPORT_SYMBOL(sys_write);
 EXPORT_SYMBOL(sys_read);
-EXPORT_SYMBOL(sys_lseek);
 EXPORT_SYMBOL(sys_open);
+#endif
+EXPORT_SYMBOL(sys_lseek);
 EXPORT_SYMBOL(sys_exit);
 EXPORT_SYMBOL(sys_wait4);
 
@@ -268,3 +278,12 @@
 EXPORT_SYMBOL_NOVERS(__up_wakeup);
 
 EXPORT_SYMBOL(get_wchan);
+
+	/* RTAI stuff */
+#ifdef CONFIG_RTHAL
+extern struct irqdesc irq_desc[NR_IRQS];
+EXPORT_SYMBOL(rthal);
+EXPORT_SYMBOL(irq_desc); 
+EXPORT_SYMBOL(do_timer);
+#endif
+
diff -urN linux-2.4.21-rmk1/arch/arm/kernel/entry-armv.S linux-2.4.21-rmk1-rthal/arch/arm/kernel/entry-armv.S
--- linux-2.4.21-rmk1/arch/arm/kernel/entry-armv.S	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/kernel/entry-armv.S	2003-07-22 13:27:48.000000000 +0200
@@ -380,6 +380,11 @@
 		ands	\irqstat, \irqstat, \irqnr
 		mov	\irqnr, #0
 		beq	1001f
+#ifdef CONFIG_RTHAL
+		tst	\irqstat, #0x04000000	@ check OSMR0 first
+		movne	\irqnr, #26
+		bne	1001f
+#endif
 		tst	\irqstat, #0xff
 		moveq	\irqstat, \irqstat, lsr #8
 		addeq	\irqnr, \irqnr, #8
@@ -674,6 +679,7 @@
 		add	r5, sp, #S_SP
 		mov	r1, lr
 		stmia	r5, {r0 - r4}			@ save sp_SVC, lr_SVC, pc, cpsr, old_ro
+
 		mrs	r9, cpsr			@ Enable interrupts if they were
 		tst	r3, #I_BIT
 		biceq	r9, r9, #I_BIT			@ previously
@@ -711,8 +717,14 @@
 		@
 		@ routine called with r0 = irq number, r1 = struct pt_regs *
 		@
+#ifndef CONFIG_RTHAL
+		adrsvc	ne, lr, 1b
+  		bne	asm_do_IRQ
+#else
+ 		ldrne	r7, .rthal			@ load pointer rthal
 		adrsvc	ne, lr, 1b
-		bne	asm_do_IRQ
+ 		ldrne	pc, [r7, #0]			@ branch to rthal.do_IRQ (1st in RTHAL)
+#endif
 		ldr	r0, [sp, #S_PSR]		@ irqs are already disabled
 		msr	spsr, r0
 		ldmia	sp, {r0 - pc}^			@ load r0 - pc, cpsr
@@ -729,6 +741,19 @@
 		add	r4, sp, #S_SP
 		stmia	r4, {r5 - r9}			@ save sp_SVC, lr_SVC, pc, cpsr, old_ro
 
+#ifdef CONFIG_RTHAL
+		ldr	r7, .rthal			@ load pointer rthal
+		ldr	r7, [r7, #8]			@ load pointer rthal.do_TRAP (3rd in RTHAL)
+		cmp	r7, #0
+		beq	2f
+		mov	r0, #4				@ SIGILL
+		mov	r1, sp				@ struct pt_regs *regs
+		mov	lr, pc
+		mov	pc, r7				@ check, if this is a relevant code
+		cmp	r0, #0				@ check return value
+		beq	1f				@ else let linux do what it has to do
+2:		
+#endif
 		adrsvc	al, r9, 1f			@ r9  = normal FP return
 		bl	call_fpe			@ lr  = undefined instr return
 
@@ -771,6 +796,9 @@
 #ifdef MULTI_CPU
 .LCprocfns:	.word	SYMBOL_NAME(processor)
 #endif
+#ifdef CONFIG_RTHAL
+.rthal:		.word	SYMBOL_NAME(rthal)
+#endif
 .LCfp:		.word	SYMBOL_NAME(fp_enter)
 
 		irq_prio_table
@@ -789,6 +817,19 @@
 		alignment_trap r7, r7, __temp_abt
 		zero_fp
 		mov	r0, r2				@ remove once everyones in sync
+
+#ifdef CONFIG_RTHAL
+		stmfd	sp!, {r0 - r2}			@ Store regs on stack
+		ldr	r0, .rthal			@ disable linux ints in rthal
+		mov	r1, #I_BIT			@ set IBIT in rthal
+		ldr	r2, [r0, #RT_MOUNTED]		@ check, if rtai is mounted
+		str	r1, [r0, #RT_INTR_FLAG]
+		cmp	r2, #0				
+		beq	goabort
+		enable_irq r2				@ enable realtime irqs
+goabort:	ldmfd	sp!, {r0 - r2}			@ Restore regs
+#endif
+
 #ifdef MULTI_CPU
 		ldr	r4, .LCprocfns			@ pass r0, r3 to
 		mov	lr, pc				@ processor code
@@ -814,12 +855,18 @@
 		zero_fp
 1:		get_irqnr_and_base r0, r6, r5, lr
 		movne	r1, sp
-		adrsvc	ne, lr, 1b
 		@
 		@ routine called with r0 = irq number, r1 = struct pt_regs *
 		@
-		bne	asm_do_IRQ
-		mov	why, #0
+#ifndef CONFIG_RTHAL
+		adrsvc	ne, lr, 1b
+  		bne	asm_do_IRQ
+#else
+ 		ldrne	r7, .rthal			@ load pointer rthal
+		adrsvc	ne, lr, 1b
+ 		ldrne	pc, [r7, #0]			@ branch to rthal.do_IRQ (1st in RTHAL)
+#endif
+		mov	why, #0				@ we come here with interrupts already disabled
 		get_current_task tsk
 		b	ret_to_user
 
@@ -840,6 +887,16 @@
 		adrsvc	al, r9, ret_from_exception	@ r9  = normal FP return
 		adrsvc	al, lr, fpundefinstr		@ lr  = undefined instr return
 
+#ifdef CONFIG_RTHAL
+		ldr	r8, .rthal			@ disable linux ints in rthal
+		mov	r10, #I_BIT			@ set IBIT in rthal
+		ldr	r4, [r8, #RT_MOUNTED]		@ check, if rtai is mounted
+		str	r10, [r8, #RT_INTR_FLAG]
+		cmp	r4, #0				
+		beq	call_fpe
+		enable_irq r8				@ enable realtime irqs
+#endif
+
 call_fpe:	get_current_task r10
 		mov	r8, #1
 		strb	r8, [r10, #TSK_USED_MATH]	@ set current->used_math
diff -urN linux-2.4.21-rmk1/arch/arm/kernel/entry-common.S linux-2.4.21-rmk1-rthal/arch/arm/kernel/entry-common.S
--- linux-2.4.21-rmk1/arch/arm/kernel/entry-common.S	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/kernel/entry-common.S	2003-07-22 13:27:48.000000000 +0200
@@ -40,12 +40,18 @@
 	teq	r1, #0				@ need_resched || sigpending
 	teqeq	r2, #0
 	bne	slow
+	
+#ifdef CONFIG_RTHAL
+	ldr	r1, .rthal			@ enable ints, as we go back to user space
+	mov	r2, #0
+	str	r2, [r1, #RT_INTR_FLAG]		
+#endif	
 	fast_restore_user_regs
 
 /*
  * Ok, we need to do extra processing, enter the slow path.
  */
-slow:	str	r0, [sp, #S_R0+S_OFF]!	@ returned r0
+slow:	str	r0, [sp, #S_R0+S_OFF]!		@ returned r0
 	teq	r1, #0
 	beq	1f
 
@@ -53,9 +59,21 @@
  * "slow" syscall return path.  "why" tells us if this was a real syscall.
  */
 reschedule:
+#ifdef CONFIG_RTHAL
+	ldr	r1, .rthal			@ disable linux ints in rthal
+	mov	r2, #I_BIT			@ set IBIT in rthal
+	str	r2, [r1, #RT_INTR_FLAG]
+	ldr	r2, [r1, #RT_MOUNTED]		@ check, if rtai is mounted
+	cmp	r2, #0				
+	beq	gosched
+	enable_irq r1				@ reenable realtime irqs
+gosched:	
+#endif
 	bl	SYMBOL_NAME(schedule)
+	
 ret_disable_irq:
 	disable_irq r1				@ ensure IRQs are disabled
+
 ENTRY(ret_to_user)
 ret_slow_syscall:
 	ldr	r1, [tsk, #TSK_NEED_RESCHED]
@@ -64,15 +82,30 @@
 	bne	reschedule
 1:	teq	r2, #0				@ sigpending => do_signal()
 	bne	__do_signal
+
 restore:
+#ifdef CONFIG_RTHAL
+	ldr	r1, .rthal			@ enable ints, as we go back to user space
+	mov	r2, #0
+	str	r2, [r1, #RT_INTR_FLAG]		
+#endif	
 	restore_user_regs
 
 __do_signal:
+#ifndef CONFIG_RTHAL
 	enable_irq r1
+#else
+	enable_irq r1
+	stmfd	sp!, {r0 - r4, fp, lr}		@ Store regs on stack
+	ldr	r1, .rthal			@ get rthal
+	mov	lr, pc
+	ldr	pc, [r1, #RT_LINUX_STI]		@ branch to rthal.linux_sti
+	ldmfd	sp!, {r0 - r4, fp, lr}		@ Restore regs
+#endif	
 	mov	r0, #0				@ NULL 'oldset'
 	mov	r1, sp				@ 'regs'
 	mov	r2, why				@ 'syscall'
-	bl	SYMBOL_NAME(do_signal)		@ note the bl above sets lr
+	bl	SYMBOL_NAME(do_signal)		@ note the bl above sets lr ????
 	disable_irq r1				@ ensure IRQs are disabled
 	b	restore
 
@@ -138,13 +171,28 @@
 	ldr	ip, [ip]
 	mcr	p15, 0, ip, c1, c0		@ update control register
 #endif
-	enable_irq ip
 
 	str	r4, [sp, #-S_OFF]!		@ push fifth arg
 
+#ifndef CONFIG_RTHAL
+	enable_irq ip
+#else
+	enable_irq ip
+	stmfd	sp!, {r0 - r4, fp, lr}		@ Store regs on stack
+	ldr	ip, .rthal
+	mov	lr, pc
+	ldr	pc, [ip, #RT_LINUX_STI]
+	ldmfd	sp!, {r0 - r4, fp, lr}		@ Restore regs
+#endif	
+
 	get_current_task tsk
 	ldr	ip, [tsk, #TSK_PTRACE]		@ check for syscall tracing
 	bic	scno, scno, #0xff000000		@ mask off SWI op-code
+#ifdef CONFIG_RTHAL
+	ldr	tbl, .rtai_magic		@ check for RTAI SRQ
+	cmp	scno, tbl			@ (use tbl for scratch)
+	beq	4f
+#endif
 	eor	scno, scno, #OS_NUMBER << 20	@ check OS number
 	adr	tbl, sys_call_table		@ load syscall table pointer
 	tst	ip, #PT_TRACESYS		@ are we tracing syscalls?
@@ -161,6 +209,21 @@
 	bcs	SYMBOL_NAME(arm_syscall)	
 	b	SYMBOL_NAME(sys_ni_syscall)	@ not private func
 
+#ifdef CONFIG_RTHAL
+4:	ldr	r7, .rthal			@ load pointer to rthal
+	ldr	r7, [r7, #4]			@ load pointer to do_SRQ, [rthal+4]
+	cmp	r7, #0
+	movne	lr, pc	             		@ call ...
+	movne	pc, r7				@ ... if available
+	str	r0, [sp, #S_R0 + S_OFF]		@ save returned r0
+	str	r1, [sp, #S_R1 + S_OFF]		@ save returned r1
+	add	sp, sp, #S_OFF			@ hmm, leave anyway
+	b	restore
+
+.rtai_magic:	.word	0x404404		@ RTAI SRQ MAGIC
+.rthal:		.word	SYMBOL_NAME(rthal)	@ RTHAL
+#endif
+
 	/*
 	 * This is the really slow path.  We're going to be doing
 	 * context switches, and waiting for our parent to respond.
diff -urN linux-2.4.21-rmk1/arch/arm/kernel/entry-header.S linux-2.4.21-rmk1-rthal/arch/arm/kernel/entry-header.S
--- linux-2.4.21-rmk1/arch/arm/kernel/entry-header.S	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/kernel/entry-header.S	2003-07-22 13:27:48.000000000 +0200
@@ -69,6 +69,24 @@
 #define S_R0		0
 #define S_OFF		8
 
+#ifdef CONFIG_RTHAL
+/* See struct rthal in include/asm/proc/system.h */
+#define RT_DO_IRQ	0
+#define RT_DO_SRQ	4
+#define RT_DO_TRP	8
+#define	RT_LINUX_CLI	12
+#define RT_LINUX_STI	16
+#define RT_GETFLAGS	20
+#define RT_SETFLAGS	24
+#define RT_GETFLAGS_CLI	28
+#define	RT_FDIS		32
+#define	RT_FEN		36
+#define RT_INTR_FLAG	40
+#define RT_DEBUG	44
+#define RT_MOUNTED	48
+#define RT_RTINTS	52
+#endif
+
 #ifdef CONFIG_CPU_32
 	.macro	set_cpsr_c, reg, mode
 #if 1
diff -urN linux-2.4.21-rmk1/arch/arm/kernel/irq.c linux-2.4.21-rmk1-rthal/arch/arm/kernel/irq.c
--- linux-2.4.21-rmk1/arch/arm/kernel/irq.c	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/kernel/irq.c	2003-07-22 13:27:48.000000000 +0200
@@ -18,6 +18,9 @@
  *  Naturally it's not a 1:1 relation, but there are similarities.
  */
 #include <linux/config.h>
+#ifdef CONFIG_RTHAL
+#include <linux/module.h>
+#endif
 #include <linux/ptrace.h>
 #include <linux/kernel_stat.h>
 #include <linux/signal.h>
@@ -111,7 +114,6 @@
 	} else if (!--desc->disable_depth) {
 		desc->probing = 0;
 		desc->unmask(irq);
-
 		/*
 		 * If the interrupt is waiting to be processed,
 		 * try to re-run it.  We can't directly run it
@@ -310,8 +312,13 @@
  */
 asmlinkage void asm_do_IRQ(int irq, struct pt_regs *regs)
 {
+#ifndef CONFIG_RTHAL
 	irq = fixup_irq(irq);
-
+#else
+	/* if RTAI is mounted, fixup is done already */
+	if (!rthal.mounted)
+		irq = fixup_irq(irq);
+#endif
 	/*
 	 * Some hardware gives randomly wrong interrupts.  Rather
 	 * than crashing, do something sensible.
@@ -686,3 +693,69 @@
 	init_arch_irq();
 	init_dma();
 }
+
+#ifdef CONFIG_RTHAL
+
+/*
+RTAI
+This is the most appropriate place to setup rthal.
+*/
+
+#include <asm/proc/hard_system.h>
+
+static void linux_cli(void)
+{
+	hard_cli();
+}
+
+static void linux_sti(void)
+{
+	hard_sti();
+}
+
+static unsigned int linux_save_flags(void)
+{
+	int flags;
+	hard_save_flags(flags);
+	return flags;
+}
+
+static unsigned int linux_save_flags_and_cli(void)
+{
+	int flags;
+	hard_save_flags_cli(flags);
+	return flags;
+}
+
+static void linux_restore_flags(unsigned int flags)
+{
+	hard_restore_flags(flags);
+}
+
+static void linux_fcli(void)
+{
+	hard_clf();
+}
+
+static void linux_fsti(void)
+{
+	hard_stf();
+}
+
+struct rt_hal rthal = {
+	.do_IRQ			= asm_do_IRQ,
+	.do_SRQ			= NULL,
+	.do_TRAP		= NULL,
+	.disint			= linux_cli,
+	.enint			= linux_sti,
+	.getflags		= linux_save_flags,
+	.setflags		= linux_restore_flags,
+	.getflags_and_cli	= linux_save_flags_and_cli,
+	.fdisint		= linux_fcli,
+	.fenint			= linux_fsti,
+	.intr_flag		= 0,
+	.debug			= NULL,
+	.mounted		= 0,
+	.rt_ints		= 0	
+};
+#endif
diff -urN linux-2.4.21-rmk1/arch/arm/mach-clps711x/time.c linux-2.4.21-rmk1-rthal/arch/arm/mach-clps711x/time.c
--- linux-2.4.21-rmk1/arch/arm/mach-clps711x/time.c	2002-08-03 02:39:42.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/mach-clps711x/time.c	2003-07-22 13:27:48.000000000 +0200
@@ -49,6 +49,14 @@
 	clps_writel(syscon, SYSCON1);
 
 	clps_writel(LATCH-1, TC2D); /* 512kHz / 100Hz - 1 */
-
+	
 	xtime.tv_sec = clps_readl(RTCDR);
+
+#ifdef CONFIG_RTHAL
+	// build a free running timer (tsc)
+	syscon = (clps_readl(SYSCON1) | SYSCON1_TC1S) & ~SYSCON_TC1M;
+	clps_writel(syscon, SYSCON1);
+	clps_writel(0,TC1D);
+#endif
+
 }
diff -urN linux-2.4.21-rmk1/arch/arm/mach-sa1100/irq.c linux-2.4.21-rmk1-rthal/arch/arm/mach-sa1100/irq.c
--- linux-2.4.21-rmk1/arch/arm/mach-sa1100/irq.c	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/mach-sa1100/irq.c	2003-07-22 13:27:48.000000000 +0200
@@ -112,7 +112,7 @@
 
 static int GPIO_11_27_spurious;		/* GPIOs that triggered when masked */
 
-static void sa1100_GPIO11_27_demux(int irq, void *dev_id,
+void sa1100_GPIO11_27_demux(int irq, void *dev_id,
 				   struct pt_regs *regs)
 {
 	int i, spurious;
@@ -138,9 +138,18 @@
 		}
 
 		for (i = 11; i <= 27; ++i) {
+#ifndef CONFIG_RTHAL
 			if (irq & (1<<i)) {
 				do_IRQ(IRQ_GPIO11 + i - 11, regs);
+			}				
+#else
+			if (irq & (1<<i)) {
+				if (!rthal.mounted)
+					do_IRQ(IRQ_GPIO11 + i - 11, regs);
+				else	
+					rthal.do_IRQ(IRQ_GPIO11 + i - 11, regs);
 			}
+#endif
 		}
 	}
 }
@@ -182,8 +191,14 @@
 			struct pt_regs dummy;
 
 			memzero(&dummy, sizeof(dummy));
+#ifndef CONFIG_RTHAL
 			do_IRQ(irq, &dummy);
-
+#else
+			if (!rthal.mounted)
+				do_IRQ(irq, &dummy);
+			else
+				rthal.do_IRQ(irq, &dummy);
+#endif
 			/* we are being called recursively from do_IRQ() */
 			return;
 		}
@@ -254,3 +269,5 @@
 	}
 	setup_arm_irq( IRQ_GPIO11_27, &GPIO11_27_irq );
 }
+
+EXPORT_SYMBOL(sa1100_GPIO11_27_demux);
diff -urN linux-2.4.21-rmk1/arch/arm/mm/fault-common.c linux-2.4.21-rmk1-rthal/arch/arm/mm/fault-common.c
--- linux-2.4.21-rmk1/arch/arm/mm/fault-common.c	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/mm/fault-common.c	2003-07-22 13:27:48.000000000 +0200
@@ -134,6 +134,11 @@
 		return;
 	}
 
+#ifdef CONFIG_RTHAL
+	if (rthal.debug)
+		rthal.debug();
+#endif	
+
 	/*
 	 * No handler, we'll have to terminate things with extreme prejudice.
 	 */
@@ -157,6 +162,11 @@
 {
 	struct siginfo si;
 
+#ifdef CONFIG_RTHAL
+	if (rthal.debug)
+		rthal.debug();
+#endif	
+
 #ifdef CONFIG_DEBUG_USER
 	printk(KERN_DEBUG "%s: unhandled page fault at pc=0x%08lx, "
 	       "lr=0x%08lx (bad address=0x%08lx, code %d)\n",
diff -urN linux-2.4.21-rmk1/arch/arm/mm/ioremap.c linux-2.4.21-rmk1-rthal/arch/arm/mm/ioremap.c
--- linux-2.4.21-rmk1/arch/arm/mm/ioremap.c	2003-07-18 09:56:36.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/arch/arm/mm/ioremap.c	2003-07-22 13:27:48.000000000 +0200
@@ -107,6 +107,9 @@
 		if (remap_area_pmd(pmd, address, end - address,
 					 pfn + (address >> PAGE_SHIFT), flags))
 			break;
+#ifdef CONFIG_RTHAL
+		set_pgdir(address, *dir);
+#endif
 		error = 0;
 		address = (address + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
diff -urN linux-2.4.21-rmk1/include/asm-arm/arch-clps711x/system.h linux-2.4.21-rmk1-rthal/include/asm-arm/arch-clps711x/system.h
--- linux-2.4.21-rmk1/include/asm-arm/arch-clps711x/system.h	2003-06-13 16:51:38.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/arch-clps711x/system.h	2003-07-22 13:27:48.000000000 +0200
@@ -23,13 +23,39 @@
 #include <asm/io.h>
 #include <asm/arch/hardware.h>
 #include <asm/hardware/clps7111.h>
+#include <asm/proc/system.h>
+#include <asm/irq.h>
 
 static inline void arch_idle(void)
 {
+#ifndef CONFIG_RTHAL
 	clps_writel(1, HALT);
 	__asm__ __volatile__(
 	"mov	r0, r0
 	mov	r0, r0");
+#else
+	static int idle = 0;
+	/* 
+	*  If RTAI is not mounted, we can safely call HALT, as the
+	*  wakeup mechanism works here. Powersaving should not be a real
+	*  issue for realtime systems.
+	*  This is just to make sure, that the system works, if somebody 
+	*  has forgotten to issue the "nohlt" in commandline
+	*/
+	if (!rthal.mounted) {
+		idle = 0;
+		clps_writel(1, HALT);
+		__asm__ __volatile__(
+		"mov	r0, r0
+		mov	r0, r0");
+	} else {
+		/* Show this only once */
+		if (!idle) {
+			idle++;
+			printk (KERN_WARNING "RTAI: Halt instruction for idle task disabled\n, Add 'nohlt' to the commandline\n");
+		}
+	}	
+#endif	
 }
 
 static inline void arch_reset(char mode)
diff -urN linux-2.4.21-rmk1/include/asm-arm/arch-epxa/system.h linux-2.4.21-rmk1-rthal/include/asm-arm/arch-epxa/system.h
--- linux-2.4.21-rmk1/include/asm-arm/arch-epxa/system.h	2003-07-18 09:56:39.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/arch-epxa/system.h	2003-07-22 11:34:18.000000000 +0200
@@ -29,11 +29,32 @@
 
 static void arch_idle(void)
 {
+#ifndef CONFIG_RTHAL
 	/*
 	 * This should do all the clock switching
 	 * and wait for interrupt tricks
 	 */
 	cpu_do_idle();
+#else
+	static int idle = 0;
+	/* 
+	*  If RTAI is not mounted, we can safely call HALT, as the
+	*  wakeup mechanism works here. Powersaving should not be a real
+	*  issue for realtime systems.
+	*  This is just to make sure, that the system works, if somebody 
+	*  has forgotten to issue the "nohlt" in commandline
+	*/
+	if (!rthal.mounted) {
+		idle = 0;
+		cpu_do_idle();
+	} else {
+		/* Show this only once */
+		if (!idle) {
+			idle++;
+			printk (KERN_WARNING "RTAI: Halt instruction for idle task disabled\n, Add 'nohlt' to the commandline\n");
+		}
+	}	
+#endif	
 }
 
 extern __inline__ void arch_reset(char mode)
diff -urN linux-2.4.21-rmk1/include/asm-arm/arch-sa1100/irq.h linux-2.4.21-rmk1-rthal/include/asm-arm/arch-sa1100/irq.h
--- linux-2.4.21-rmk1/include/asm-arm/arch-sa1100/irq.h	2001-08-12 20:14:00.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/arch-sa1100/irq.h	2003-07-22 13:27:48.000000000 +0200
@@ -4,6 +4,9 @@
  * Author: Nicolas Pitre
  */
 
+#ifndef _ASM_ARCH_IRQ_H
+#define _ASM_ARCH_IRQ_H
+
 #define fixup_irq(x)	(x)
 
 /*
@@ -11,3 +14,6 @@
  * Since it doesn't exist elsewhere, we'll put it here for now.
  */
 extern void do_IRQ(int irq, struct pt_regs *regs);
+extern void sa1100_GPIO11_27_demux(int irq, void *dev_id, struct pt_regs *regs);
+
+#endif /* _ASM_ARCH_IRQ_H */
diff -urN linux-2.4.21-rmk1/include/asm-arm/arch-sa1100/system.h linux-2.4.21-rmk1-rthal/include/asm-arm/arch-sa1100/system.h
--- linux-2.4.21-rmk1/include/asm-arm/arch-sa1100/system.h	2003-07-18 09:56:40.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/arch-sa1100/system.h	2003-07-22 13:27:48.000000000 +0200
@@ -8,7 +8,28 @@
 
 static inline void arch_idle(void)
 {
+#ifndef CONFIG_RTHAL
 	cpu_do_idle();
+#else
+	static int idle = 0;
+	/* 
+	*  If RTAI is not mounted, we can safely call HALT, as the
+	*  wakeup mechanism works here. Powersaving should not be a real
+	*  issue for realtime systems.
+	*  This is just to make sure, that the system works, if somebody 
+	*  has forgotten to issue the "nohlt" in commandline
+	*/
+	if (!rthal.mounted) {
+		idle = 0;
+		cpu_do_idle();
+	} else {
+		/* Show this only once */
+		if (!idle) {
+			idle++;
+			printk (KERN_WARNING "RTAI: Idle mode for idle task disabled\n, Add 'nohlt' to the commandline\n");
+		}
+	}
+#endif	
 }
 
 #ifdef CONFIG_SA1100_VICTOR
diff -urN linux-2.4.21-rmk1/include/asm-arm/atomic.h linux-2.4.21-rmk1-rthal/include/asm-arm/atomic.h
--- linux-2.4.21-rmk1/include/asm-arm/atomic.h	2003-07-18 09:56:40.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/atomic.h	2003-07-22 13:27:48.000000000 +0200
@@ -27,7 +27,18 @@
 #define ATOMIC_INIT(i)	{ (i) }
 
 #ifdef __KERNEL__
+
+#ifdef CONFIG_RTHAL
+/* RTAI Modification, azu */
+#include <asm/proc/hard_system.h>
+#define my_atomic_save_flags_cli(x) hard_save_flags_cli(x)
+#define my_atomic_restore_flags(x) hard_restore_flags(x)
+#else
+/* Normal mode */
 #include <asm/proc/system.h>
+#define my_atomic_save_flags_cli(x) local_irq_save(x)
+#define my_atomic_restore_flags(x) local_irq_restore(x)
+#endif
 
 #define atomic_read(v)	((v)->counter)
 #define atomic_set(v,i)	(((v)->counter) = (i))
@@ -36,36 +47,36 @@
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	v->counter += i;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 }
 
 static inline void atomic_sub(int i, volatile atomic_t *v)
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	v->counter -= i;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 }
 
 static inline void atomic_inc(volatile atomic_t *v)
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	v->counter += 1;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 }
 
 static inline void atomic_dec(volatile atomic_t *v)
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	v->counter -= 1;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 }
 
 static inline int atomic_dec_and_test(volatile atomic_t *v)
@@ -73,10 +84,10 @@
 	unsigned long flags;
 	int val;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	val = v->counter;
 	v->counter = val -= 1;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 
 	return val == 0;
 }
@@ -86,10 +97,10 @@
 	unsigned long flags;
 	int val;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	val = v->counter;
 	v->counter = val += i;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 
 	return val < 0;
 }
@@ -98,9 +109,9 @@
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	my_atomic_save_flags_cli(flags);
 	*addr &= ~mask;
-	local_irq_restore(flags);
+	my_atomic_restore_flags(flags);
 }
 
 /* Atomic operations are already serializing on ARM */
diff -urN linux-2.4.21-rmk1/include/asm-arm/hw_irq.h linux-2.4.21-rmk1-rthal/include/asm-arm/hw_irq.h
--- linux-2.4.21-rmk1/include/asm-arm/hw_irq.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/hw_irq.h	2003-07-22 13:27:48.000000000 +0200
@@ -0,0 +1,7 @@
+/*
+ * hw_irq.h
+ *
+ * just a dummy for include/linux/irq.c
+ */
+
+#include <asm/irq.h>
diff -urN linux-2.4.21-rmk1/include/asm-arm/irq.h linux-2.4.21-rmk1-rthal/include/asm-arm/irq.h
--- linux-2.4.21-rmk1/include/asm-arm/irq.h	1999-06-17 10:11:35.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/irq.h	2003-07-22 13:27:48.000000000 +0200
@@ -24,5 +24,9 @@
 extern void disable_irq(unsigned int);
 extern void enable_irq(unsigned int);
 
+#ifdef CONFIG_RTHAL
+extern struct rt_hal rthal;
+#endif
+
 #endif
 
diff -urN linux-2.4.21-rmk1/include/asm-arm/pgalloc.h linux-2.4.21-rmk1-rthal/include/asm-arm/pgalloc.h
--- linux-2.4.21-rmk1/include/asm-arm/pgalloc.h	2001-08-12 20:14:00.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/pgalloc.h	2003-07-22 13:27:48.000000000 +0200
@@ -138,4 +138,34 @@
 
 extern int do_check_pgt_cache(int, int);
 
+#ifdef CONFIG_RTHAL
+extern inline void set_pgdir(unsigned long address, pgd_t entry)
+{
+	struct task_struct * p;
+	pgd_t *pgd;
+#ifdef CONFIG_SMP
+	int i;
 #endif
+
+	read_lock(&tasklist_lock);
+	for_each_task(p) {
+		if (!p->mm)
+			continue;
+		*pgd_offset(p->mm,address) = entry;
+	}
+	read_unlock(&tasklist_lock);
+#ifndef CONFIG_SMP
+	for (pgd = (pgd_t *)pgd_quicklist; pgd; pgd = (pgd_t *)*(unsigned long *)pgd)
+		pgd[address >> PGDIR_SHIFT] = entry;
+#else
+	/* To pgd_alloc/pgd_free, one holds master kernel lock and so does our callee, so we can
+	   modify pgd caches of other CPUs as well. -jj */
+	for (i = 0; i < NR_CPUS; i++)
+		for (pgd = (pgd_t *)cpu_data[i].pgd_quick; pgd; pgd = (pgd_t *)*(unsigned long *)pgd)
+			pgd[address >> PGDIR_SHIFT] = entry;
+#endif
+}
+#endif /* CONFIG_RTHAL */
+
+#endif
+
diff -urN linux-2.4.21-rmk1/include/asm-arm/proc-armv/assembler.h linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/assembler.h
--- linux-2.4.21-rmk1/include/asm-arm/proc-armv/assembler.h	2000-09-19 00:15:24.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/assembler.h	2003-07-22 13:27:48.000000000 +0200
@@ -37,6 +37,7 @@
 /*
  * Save the current IRQ state and disable IRQs.  Note that this macro
  * assumes FIQs are enabled, and that the processor is in SVC mode.
+ * Clean only used in asm/arm/lib/bit....
  */
 	.macro	save_and_disable_irqs, oldcpsr, temp
 	mrs	\oldcpsr, cpsr
@@ -47,6 +48,7 @@
 /*
  * Restore interrupt state previously stored in a register.  We don't
  * guarantee that this will preserve the flags.
+ * Clean only used in asm/arm/lib/bit....
  */
 	.macro	restore_irqs, oldcpsr
 	msr	cpsr_c, \oldcpsr
diff -urN linux-2.4.21-rmk1/include/asm-arm/proc-armv/hard_system.h linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/hard_system.h
--- linux-2.4.21-rmk1/include/asm-arm/proc-armv/hard_system.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/hard_system.h	2003-07-22 13:27:48.000000000 +0200
@@ -0,0 +1,115 @@
+/*
+RTAI
+The hard manipulation for enabling/disabling interrupts and related stuff.
+*/
+
+/*
+ *  linux/include/asm-arm/proc-armv/hard_system.h
+ *
+ *  Copyright (C) 1996 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#ifndef __ASM_PROC_HARD_SYSTEM_H
+#define __ASM_PROC_HARD_SYSTEM_H
+
+#include <linux/config.h>
+
+/*
+ * Save the current interrupt enable state & disable IRQs
+ */
+#define hard_save_flags_cli(x)					\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ save_flags_cli\n"	\
+"	orr	%1, %0, #128\n"					\
+"	msr	cpsr_c, %1"					\
+	: "=r" (x), "=r" (temp)					\
+	:							\
+	: "memory");						\
+	})
+	
+/*
+ * Enable IRQs
+ */
+#define hard_sti()							\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ sti\n"		\
+"	bic	%0, %0, #128\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Disable IRQs
+ */
+#define hard_cli()							\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ cli\n"		\
+"	orr	%0, %0, #128\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Enable FIQs
+ */
+#define hard_stf()							\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ stf\n"		\
+"	bic	%0, %0, #64\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Disable FIQs
+ */
+#define hard_clf()							\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ clf\n"		\
+"	orr	%0, %0, #64\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * save current IRQ & FIQ state
+ */
+#define hard_save_flags(x)						\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ save_flags\n"		\
+	  : "=r" (x)						\
+	  :							\
+	  : "memory")
+
+/*
+ * restore saved IRQ & FIQ state
+ */
+#define hard_restore_flags(x)					\
+	__asm__ __volatile__(					\
+	"msr	cpsr_c, %0		@ restore_flags\n"	\
+	:							\
+	: "r" (x)						\
+	: "memory")
+
+#endif
diff -urN linux-2.4.21-rmk1/include/asm-arm/proc-armv/locks.h linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/locks.h
--- linux-2.4.21-rmk1/include/asm-arm/proc-armv/locks.h	2003-07-18 09:56:40.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/locks.h	2003-07-22 13:27:48.000000000 +0200
@@ -7,6 +7,8 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
+ * RTHAL checked. Clean !
+ *
  *  Interrupt safe locking assembler. 
  */
 #ifndef __ASM_PROC_LOCKS_H
diff -urN linux-2.4.21-rmk1/include/asm-arm/proc-armv/system.h linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/system.h
--- linux-2.4.21-rmk1/include/asm-arm/proc-armv/system.h	2003-07-18 09:56:40.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/proc-armv/system.h	2003-07-22 13:27:48.000000000 +0200
@@ -42,6 +42,38 @@
 #define vectors_base()	(0)
 #endif
 
+#ifdef CONFIG_RTHAL
+#include <asm/proc/ptrace.h>
+
+/*
+RTAI
+Definition of rthal.
+Do not change this structure unless you know what you are doing!
+Filled with values in arch/arm/kernel/irq.c
+*/
+
+struct rt_hal {
+	void (*do_IRQ)(unsigned int, struct pt_regs*); /* must be first - arch/arm/kernel/entry-armv.S */
+	long long (*do_SRQ)(unsigned int, unsigned long); /* must be second - arch/arm/kernel/entry-common.S */
+	int (*do_TRAP)(unsigned int, struct pt_regs*); /* must be third - arch/arm/kernel/entry-armv.S */
+	void (*disint)(void);
+	void (*enint)(void);
+	unsigned int (*getflags)(void);
+	void (*setflags)(unsigned int);
+	unsigned int (*getflags_and_cli)(void);
+	void (*fdisint)(void);
+	void (*fenint)(void);
+	unsigned long intr_flag;
+	void (*debug)(void);
+	int mounted;
+	unsigned long rt_ints;
+} __attribute__ ((__aligned__ (32)));
+
+extern struct rt_hal rthal;
+
+#endif
+
+#ifndef CONFIG_RTHAL
 /*
  * Save the current interrupt enable state & disable IRQs
  */
@@ -150,6 +182,23 @@
 	:							\
 	: "r" (x)						\
 	: "memory")
+#else
+#define local_irq_save(x)      	do { x = rthal.getflags_and_cli(); } while (0)
+#define __save_flags_cli(x)    	do { x = rthal.getflags_and_cli(); } while (0)
+#define local_irq_enable()     	do { rthal.enint(); } while (0)
+#define __sti()                	do { rthal.enint(); } while (0)
+#define local_irq_disable()    	do { rthal.disint(); } while (0)
+#define __cli()               	do { rthal.disint(); } while (0)
+#define __stf()                	do { rthal.fenint(); } while (0)
+#define __clf()                	do { rthal.fdisint(); } while (0)
+#define local_save_flags(x)    	do { x = rthal.getflags(); } while (0)
+#define __save_flags(x)        	do { x = rthal.getflags(); } while (0)
+#define local_irq_restore(x)   	do { rthal.setflags(x); } while (0)
+#define __restore_flags(x)     	do { rthal.setflags(x); } while (0)
+#define local_irq_set(x)	do {c = rthal.getflags(); rthal.enint(); } while (0)
+
+#include <asm/proc/hard_system.h>
+#endif	
 
 #if defined(CONFIG_CPU_SA1100) || defined(CONFIG_CPU_SA110)
 /*
@@ -177,6 +226,7 @@
 
 	switch (size) {
 #ifdef swp_is_buggy
+#ifndef CONFIG_RTHAL /* original stuff */
 		case 1:
 			local_irq_save(flags);
 			ret = *(volatile unsigned char *)ptr;
@@ -190,6 +240,21 @@
 			*(volatile unsigned long *)ptr = x;
 			local_irq_restore(flags);
 			break;
+#else /* CONFIG_RTHAL keep it atomic */
+		case 1:
+			hard_save_flags_cli(flags);
+			ret = *(volatile unsigned char *)ptr;
+			*(volatile unsigned char *)ptr = x;
+			hard_restore_flags(flags);
+			break;
+
+		case 4:
+			hard_save_flags_cli(flags);
+			ret = *(volatile unsigned long *)ptr;
+			*(volatile unsigned long *)ptr = x;
+			hard_restore_flags(flags);
+			break;
+#endif /* CONFIG_RTHAL */
 #else
 		case 1:	__asm__ __volatile__ ("swpb %0, %1, [%2]"
 					: "=&r" (ret)
diff -urN linux-2.4.21-rmk1/include/asm-arm/system.h linux-2.4.21-rmk1-rthal/include/asm-arm/system.h
--- linux-2.4.21-rmk1/include/asm-arm/system.h	2003-07-18 09:56:40.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/include/asm-arm/system.h	2003-07-22 13:27:48.000000000 +0200
@@ -55,6 +55,7 @@
 #define nop() __asm__ __volatile__("mov\tr0,r0\t@ nop\n\t");
 
 #define prepare_to_switch()    do { } while(0)
+#define end_switch()           do { } while(0)
 
 /*
  * switch_to(prev, next) should switch from task `prev' to `next'
@@ -70,11 +71,15 @@
 	} while (0)
 
 /* For spinlocks etc */
+#ifndef CONFIG_RTHAL
 #define __save_flags_cli(x)	local_irq_save(x)
 #define __save_flags(x)		local_save_flags(x)
 #define __restore_flags(x)	local_irq_restore(x)
 #define __cli()			local_irq_disable()
 #define __sti()			local_irq_enable()
+#else
+#include <asm/proc/hard_system.h>
+#endif
 
 #ifdef CONFIG_SMP
 #error SMP not supported
diff -urN linux-2.4.21-rmk1/Makefile linux-2.4.21-rmk1-rthal/Makefile
--- linux-2.4.21-rmk1/Makefile	2003-07-18 09:56:33.000000000 +0200
+++ linux-2.4.21-rmk1-rthal/Makefile	2003-07-22 13:27:48.000000000 +0200
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 4
 SUBLEVEL = 21
-EXTRAVERSION =-rmk1
+EXTRAVERSION =-rmk1-rthal
 
 KERNELRELEASE=$(VERSION).$(PATCHLEVEL).$(SUBLEVEL)$(EXTRAVERSION)
 
